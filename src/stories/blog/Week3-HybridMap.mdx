import { Meta } from "@storybook/blocks";

<Meta title="Blog & Writing/3. Finding the Hybrid" />

# Finding the Hybrid: NLP-Powered Map Search

**January 29 - February 1, 2026** ¬∑ 10 min read

---

It was late on January 23rd when I created the rough proof-of-concept. Just the AI search input next to a map. No polish, just the two pieces side-by-side to see how they felt together.

Honestly? I didn't expect much. I'd already tried conversational UI (tedious). I'd tried AI-powered search input (gimmicky). This was probably going to be another dead end.

But I opened the component anyway, typed "3 bedroom condo in Liberty Village," and watched what happened.

The map moved. Centered on Liberty Village. The filters updated. Properties appeared.

And I just... stared at it.

Something felt different. Not the "oh this is clever" different. The "oh, _this_ is how it should work" different.

But I didn't trust it yet. I'd been wrong twice before. The chatbot _felt_ right at first. The AI search input _seemed_ elegant. Why would this be any different?

So I sat there, staring at the proof-of-concept, trying to figure out what was wrong with it.

And I couldn't find anything.

---

## The Realization (That I Didn't Want to Believe)

Here's the thing: I didn't want to rewrite everything _again_.

I'd already deleted the chatbot approach. I'd already deleted 2,016 lines from the AI search input. And now I was looking at another complete rewrite?

But the proof-of-concept kept nagging at me. Every time I used it, it just... worked. Type. Map moves. Filters update. Refine visually.

Fast. Intuitive. No friction.

On January 29th, I gave in and committed the rewrite:

```bash
feat: add AI-powered map listings component with NLP search

 46 files changed, 8626 insertions(+), 2016 deletions(-)
```

**8,626 lines added. 2,016 deleted.**

This better be worth it.

---

## What I Missed (Twice)

Property search is fundamentally spatial. When someone says "I want to live in Liberty Village," they're not describing a database query - they're describing a _place_.

And places are best understood visually.

This seems obvious now. But I'd spent three months trying to make natural language the _primary_ interface. Chat. Then AI search input. Both trying to make typing the main interaction.

I'd been solving the wrong problem.

Think about how you'd actually search for a home:

- Open a map
- Look around a neighborhood
- See what's available
- Zoom in on interesting areas
- Filter down to what you can afford

The map isn't a _result visualization_. It's the primary interface.

So what role does natural language play?

**Getting you there fast.** That's it. Not replacing the map. Not being the interface. Just... a shortcut.

---

## The New Architecture

Instead of forcing users to type everything, I flipped it:

```
1. User TYPES intent: "3br condo in Liberty Village under 800k"
2. Repliers NLP parses it into:
   - Location: Liberty Village (lat: 43.639, lng: -79.403)
   - Filters: 3 bedrooms, Condo, Max $800k
3. Map auto-centers on Liberty Village
4. Filters auto-populate (bedrooms: 3, property type: Condo, price: $800k)
5. User REFINES visually:
   - Click a different neighborhood on the map
   - Adjust price slider
   - Toggle property types
   - Explore freely
```

Natural language for the **initial intent**. Visual UI for **exploration and refinement**.

Hybrid.

---

## The Implementation: Actually Reading the Docs

The breakthrough came from actually reading the Repliers NLP API response.

I know. Embarrassing. I'd been using this API for months and apparently hadn't looked closely at what it returned.

Here's what it gives you:

```json
{
  "search_url": "https://api.repliers.io/listings?...",
  "summary": "3 bedroom condos in Liberty Village under $800,000",
  "locations": [
    {
      "name": "Liberty Village",
      "type": "neighborhood",
      "geometry": {
        "type": "Polygon",
        "coordinates": [[[lng, lat], ...]]
      },
      "center": [43.639, -79.403],
      "zoom": 14
    }
  ]
}
```

**The API already gives you lat/long, boundaries, and zoom level.**

I'd been planning to add a separate Mapbox geocoding call. I'd even roughed out the code for it. But the data was already sitting there in the NLP response.

How many hours had I wasted over-engineering when the solution was already there?

```typescript
/**
 * Extract location data from Repliers NLP response
 * Returns coordinates, boundaries, and recommended zoom
 */
export function extractLocationFromNLP(response: NLPResponse) {
  const location = response.locations?.[0];

  if (!location) return null;

  return {
    center: location.center, // [lat, lng]
    boundaries: location.geometry, // GeoJSON polygon
    zoom: location.zoom || 14, // Recommended zoom level
    name: location.name, // "Liberty Village"
    type: location.type, // "neighborhood"
  };
}
```

One API call. Everything you need to center the map perfectly.

I could have saved myself a week of work if I'd just read the API response carefully from the start.

---

## Building SearchFeedback: Showing Your Work

Here's the thing about AI-powered features: users don't trust them unless you show what the AI understood.

I learned this the hard way. The initial version didn't have the SearchFeedback component. Users would type something, the map would move, and they'd just... sit there, confused.

"Did it work? What's it searching for? Why am I seeing these results?"

Right. Show your work.

So I built a SearchFeedback component that displays the interpretation:

```tsx
export function SearchFeedback({ prompt, url, summary, filters }) {
  // Analyze what was captured from the user's prompt
  const captured = [
    { label: "Neighborhood", value: "Liberty Village", icon: <MapPin /> },
    { label: "Bedrooms", value: "3", icon: <Bed /> },
    { label: "Property Type", value: "Condo", icon: <Home /> },
    { label: "Price", value: "Under $800,000", icon: <DollarSign /> },
  ];

  return (
    <div className="search-feedback">
      <div className="prompt">You searched: "{prompt}"</div>

      <div className="interpretation">{summary}</div>

      <div className="captured-criteria">
        {captured.map((item) => (
          <div className="criterion">
            {item.icon} {item.label}: {item.value}
          </div>
        ))}
      </div>
    </div>
  );
}
```

The UI shows:

```
You searched: "3br condo in Liberty Village under 800k"

Showing: 3 bedroom condos in Liberty Village under $800,000

Captured criteria:
üìç Neighborhood: Liberty Village
üõèÔ∏è Bedrooms: 3
üè† Property Type: Condo
üí∞ Price: Under $800,000
```

This builds trust. Users see exactly what the AI understood, and they can immediately spot if something was missed or misinterpreted.

---

## The Filter Parser: URL to State

The Repliers NLP API returns a ready-to-use search URL with all the parameters:

```
https://api.repliers.io/listings?propertyType=Condo%20Apt&minBeds=3&
maxPrice=800000&city=Toronto&neighborhood=Liberty%20Village
```

I needed to parse this back into my component's filter state:

```typescript
export function parseNLPUrl(url: string): Partial<MapFilters> {
  const urlObj = new URL(url);
  const params = urlObj.searchParams;

  const filters: Partial<MapFilters> = {};

  // Property Type
  const propertyType = params.get("propertyType");
  if (propertyType) {
    filters.propertyTypes = propertyType.split(",").map((t) => t.trim());
  }

  // Bedrooms
  const minBeds = params.get("minBeds");
  if (minBeds) {
    const value = parseInt(minBeds);
    filters.bedrooms = value >= 5 ? "5+" : value.toString();
  }

  // Price Range
  const maxPrice = params.get("maxPrice");
  if (maxPrice) filters.maxPrice = parseInt(maxPrice);

  return filters;
}
```

Now when the NLP search completes:

1. Parse the URL into filter state
2. Update the UI filters to match
3. User sees exactly what criteria are active
4. User can adjust any filter with traditional UI

---

## The Search Panel: Chat-Like but Not Chat

I kept the familiar chat interface pattern for the input, but made it clear this isn't a conversation:

```tsx
<SearchPanel>
  {!hasSearched && (
    <InspirationChips>
      Try: "3br condo in Liberty Village" Or: "House under 800k near Queen West"
    </InspirationChips>
  )}

  <SearchInput
    placeholder="Try: '3br condo in Liberty Village under 800k'"
    onSearch={handleNLPSearch}
    loading={searching}
  />

  {hasSearched && (
    <SearchFeedback
      prompt={lastQuery}
      url={nlpResponse.search_url}
      summary={nlpResponse.summary}
      filters={parsedFilters}
    />
  )}
</SearchPanel>
```

Before searching: show inspiration chips with examples.
After searching: show what was understood.

Each search is independent - no conversation history. Because property search is exploratory, not conversational.

---

## February 1st: The Embarrassing Optimization

The initial implementation worked, but I was still calling the Locations API separately for geocoding.

Let me say that again: I'd already discovered the NLP response contained location data. I'd extracted it. I'd used it to center the map.

And I was _still_ making a separate geocoding call out of habit.

On February 1st, I finally noticed:

```bash
feat: optimize NLP response usage and add search feedback UI

Changes:
- Enhanced NLP response handling to use location data directly,
  eliminating unnecessary calls to /locations endpoint
- Added Location and NLPResponse TypeScript interfaces
- Created extractLocationFromNLP() utility function
- Implemented SearchFeedback component with chat-like UI
- Added comprehensive console logging for debugging

Benefits:
- Reduced API calls by using NLP response data directly
- Improved user understanding of AI interpretation
- Better UX with visual feedback on applied filters
```

From two API calls (NLP + Locations) down to one (NLP only).

Sometimes the best optimization is just... reading the response more carefully.

Or, you know, reading it at all.

---

## The Components: Clean Separation

The final structure:

```
ai-map-listings/
‚îú‚îÄ‚îÄ ai-map-listings.tsx (1,453 lines - main component)
‚îú‚îÄ‚îÄ components/
‚îÇ   ‚îú‚îÄ‚îÄ SearchPanel/
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SearchPanel.tsx (326 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SearchInput.tsx (103 lines)
‚îÇ   ‚îÇ   ‚îú‚îÄ‚îÄ SearchFeedback.tsx (231 lines)
‚îÇ   ‚îÇ   ‚îî‚îÄ‚îÄ InspirationChips.tsx
‚îÇ   ‚îî‚îÄ‚îÄ FilterSections/
‚îÇ       ‚îú‚îÄ‚îÄ BedroomBathroomFilter.tsx
‚îÇ       ‚îú‚îÄ‚îÄ PriceRangeFilter.tsx
‚îÇ       ‚îî‚îÄ‚îÄ PropertyTypeFilter.tsx
‚îú‚îÄ‚îÄ hooks/
‚îÇ   ‚îî‚îÄ‚îÄ useNLPSearch.ts (108 lines)
‚îî‚îÄ‚îÄ utils/
    ‚îú‚îÄ‚îÄ nlp-parser.ts (116 lines)
    ‚îî‚îÄ‚îÄ location-geocoder.ts (99 lines)
```

Each piece has a clear responsibility:

- **SearchPanel**: Handles NLP input and feedback
- **FilterSections**: Traditional filter UI
- **useNLPSearch**: Manages NLP API calls and state
- **nlp-parser**: Converts NLP URLs to filter state
- **location-geocoder**: Extracts location data from responses

---

## What Makes It Work (I Think)

Looking back, I can identify four decisions that mattered. Though honestly, half of these were accidents:

### 1. NLP Is Enhancement, Not Replacement

The map works perfectly without any NLP search. Users can:

- Pan around the map
- Click filters
- Explore visually

NLP is just a faster way to express initial intent.

### 2. Each Search Starts Fresh

No conversation history. No nlpId persistence between searches.

Why? Because users want to try different things:

- "3br in Liberty Village" ‚Üí see results
- "Actually, show me High Park" ‚Üí fresh search
- "What about 2br?" ‚Üí fresh search

Exploration is non-linear. Don't force it into a conversational flow.

### 3. Show the Interpretation

The SearchFeedback component is crucial. It answers:

- Did the AI understand correctly?
- What criteria are active?
- What got missed?

Transparency builds trust.

### 4. Visual Refinement > Typed Refinement

After the initial NLP search, users refine with:

- Price sliders
- Bedroom buttons
- Property type checkboxes
- Map panning/zooming

Not by typing "actually make it 850k" into a search box.

---

## The User Experience

Here's the full flow:

**User types**: "3 bedroom condo in Liberty Village under 800k"

_[500ms later, NLP parses]_

**Map**: Smoothly centers on Liberty Village
**Filters**: Update to 3 beds, Condo, $800k max
**SearchFeedback**: Shows interpretation

**User sees 12 properties on the map**

**User**: Clicks price slider, adjusts to $850k
**Map**: Updates immediately with 4 more properties

**User**: Pans map west to see nearby neighborhoods
**Map**: Shows properties in adjacent areas

**User**: Types new search: "house near Queen West"
**Map**: Centers on Queen West, clears condo filter
**SearchFeedback**: Shows new interpretation

Fast. Visual. Exploratory.

---

## The Metrics That Matter

After deploying to Storybook, I watched the console logs (yes, I left debugging logs in on purpose):

```
NLP Request: "3br condo liberty village under 800k"
NLP Response time: 847ms
Location extracted: Liberty Village (43.639, -79.403)
Filters parsed: {bedrooms: 3, propertyTypes: ['Condo'], maxPrice: 800000}
Map centered: [43.639, -79.403], zoom: 14
Results loaded: 12 properties
```

Under a second from typing to seeing results on a centered map.

No separate geocoding call. One API request. Clean.

---

## What I Learned (The Hard Way)

### Maps > Chat for Spatial Tasks

Property search is inherently spatial. Took me three months and two failed approaches to figure that out.

### Read the API Response (Seriously, Read It)

I almost added a separate Locations API call for geocoding. The data was already in the NLP response, staring me in the face.

RTFM isn't just for beginners.

### Show Your Work

The SearchFeedback component wasn't in my original plan. Users were confused without it. Another thing I should have anticipated but didn't.

### Hybrid Beats Pure

Not AI-only. Not traditional-only. Both. Turns out users don't want to be forced into a single interaction model. Who knew? (Everyone. Everyone knew this.)

### Delete Without Guilt

Those 2,016 deleted lines from the AI Search Input? They taught me what doesn't work, which informed what does.

Still hurt to delete them though.

---

## Try It Yourself

[AI Map Listings Component](/?path=/story/pocs-ai-map-listings--default)

Try these searches:

- "3 bedroom condo in Liberty Village"
- "House under 800k in Leslieville"
- "2br apartment near Queen West"

Watch how the map centers and filters populate. Then refine visually.

---

**Commits referenced**: `0bfe16e`, `a359e03`, `b79fe88`

**Next**: Week 4: Lessons from 3 Months of NLP Experimentation ‚Üí
